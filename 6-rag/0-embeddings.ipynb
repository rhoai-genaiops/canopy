{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05e1451-95f8-4dba-9a77-29b446e5304f",
   "metadata": {},
   "source": [
    "# üî¢ Understanding Word Embeddings\n",
    "\n",
    "Welcome to the world of embeddings! Before we dive into building vector databases, let's understand the fundamental concept that makes it all possible: **word embeddings**.\n",
    "\n",
    "Think of embeddings as a way to teach computers the *meaning* of words by converting them into numbers. This simple concept revolutionizes how AI systems understand and search through text.\n",
    "\n",
    "Let's explore how this magic works! ‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u0csgcg862b",
   "metadata": {},
   "source": [
    "## üì¶ Install Required Packages\n",
    "\n",
    "Let's install the basic tools we need to create and work with embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97pf6pfm0ne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the essential embedding library\n",
    "!pip install -q sentence-transformers==3.0.1 scikit-learn==1.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "omb5tiogb8",
   "metadata": {},
   "source": [
    "## üìö Import Libraries\n",
    "\n",
    "Import the tools we'll use to create embeddings and measure similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tr7tsri837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "print(\"üß† Ready to explore embeddings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-example",
   "metadata": {},
   "source": [
    "## üî¢ From Words to Numbers: A Simple Example\n",
    "\n",
    "Here's how different words become different vectors (simplified to just 4 dimensions for illustration):\n",
    "\n",
    "- `\"dog\"` ‚Üí [0.2, 0.8, 0.1, 0.6] \n",
    "- `\"puppy\"` ‚Üí [0.3, 0.7, 0.2, 0.5] (similar to dog - both canines)\n",
    "- `\"cat\"` ‚Üí [0.1, 0.6, 0.8, 0.3] (different but some similarity - still a pet)\n",
    "- `\"car\"` ‚Üí [0.9, 0.1, 0.2, 0.1] (completely different - not an animal)\n",
    "\n",
    "In real embeddings, these vectors have hundreds or thousands of dimensions, capturing subtle meaning relationships that make semantic search possible!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ig53v1qn",
   "metadata": {},
   "source": [
    "## üß™ Let's Create Real Embeddings!\n",
    "\n",
    "Now let's see this in action! We'll convert those same words into actual embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mhq43gkwk7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Our example words from the diagram\n",
    "words = [\"dog\", \"puppy\", \"cat\", \"car\"]\n",
    "\n",
    "# Convert words to embeddings (vectors)\n",
    "embeddings = model.encode(words)\n",
    "\n",
    "print(\"üî¢ Converting words to vectors:\")\n",
    "for word, embedding in zip(words, embeddings):\n",
    "    print(f\"'{word}' ‚Üí vector with {len(embedding)} dimensions\")\n",
    "    print(f\"   First 5 values: {embedding[:5]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vector-magic",
   "metadata": {},
   "source": [
    "## ‚ú® The Vector Magic\n",
    "\n",
    "1. **Text ‚Üí Numbers**: Every piece of text gets converted into a list of numbers (a vector) that captures its meaning\n",
    "2. **Similarity Search**: When you ask a question, the system finds vectors that are close in distance\n",
    "3. **Lightning Fast**: Even with millions of documents, searches happen in milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x09nyg4my7",
   "metadata": {},
   "source": [
    "## üîç Testing Similarity\n",
    "\n",
    "Let's measure how similar our words are to each other. The computer will tell us which words are most related!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u3zd1eqqkf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity between 'dog' and all other words\n",
    "dog_embedding = embeddings[0].reshape(1, -1)  # 'dog' is first word\n",
    "other_embeddings = embeddings[1:]  # puppy, cat, car\n",
    "\n",
    "# Calculate cosine similarity (higher = more similar)\n",
    "similarities = cosine_similarity(dog_embedding, other_embeddings)[0]\n",
    "\n",
    "print(\"üêï How similar is 'dog' to other words?\")\n",
    "print()\n",
    "for word, similarity in zip(words[1:], similarities):\n",
    "    print(f\"dog ‚Üî {word}: {similarity:.3f}\")\n",
    "    \n",
    "print()\n",
    "print(\"üìä Notice:\")\n",
    "print(\"‚Ä¢ 'dog' and 'puppy' are most similar (both canines)\")\n",
    "print(\"‚Ä¢ 'dog' and 'cat' have some similarity (both pets)\")\n",
    "print(\"‚Ä¢ 'dog' and 'car' are least similar (totally different concepts)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ycbz1iw7b2",
   "metadata": {},
   "source": [
    "## üéÆ Try It Yourself!\n",
    "\n",
    "Want to test similarity between your own words or phrases? Run the cell below and experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exrch95i6x",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own words or phrases!\n",
    "# Change these to anything you want to compare\n",
    "test_words = [\n",
    "    \"machine learning\",\n",
    "    \"artificial intelligence\", \n",
    "    \"deep learning\",\n",
    "    \"cooking recipes\"\n",
    "]\n",
    "\n",
    "# Create embeddings\n",
    "test_embeddings = model.encode(test_words)\n",
    "\n",
    "# Compare first phrase with all others\n",
    "base_embedding = test_embeddings[0].reshape(1, -1)\n",
    "other_test_embeddings = test_embeddings[1:]\n",
    "test_similarities = cosine_similarity(base_embedding, other_test_embeddings)[0]\n",
    "\n",
    "print(f\"üß™ How similar is '{test_words[0]}' to other phrases?\")\n",
    "print()\n",
    "for phrase, similarity in zip(test_words[1:], test_similarities):\n",
    "    print(f\"'{test_words[0]}' ‚Üî '{phrase}': {similarity:.3f}\")\n",
    "\n",
    "print()\n",
    "print(\"üí° Try changing the test_words list above and rerun to experiment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## üöÄ What's Next?\n",
    "\n",
    "Now that you understand how embeddings work conceptually, you're ready to:\n",
    "\n",
    "- **Build a real vector database** using Milvus\n",
    "- **Generate actual embeddings** from text\n",
    "- **Implement semantic search** for educational content\n",
    "- **See the magic in action** with real similarity scores\n",
    "\n",
    "Continue to the next notebook: **`1-vector-databases.ipynb`** to start building your production vector database! üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

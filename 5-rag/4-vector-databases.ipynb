{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05e1451-95f8-4dba-9a77-29b446e5304f",
   "metadata": {},
   "source": [
    "# 🗃️ Vector Database: The Heart of Educational RAG\n",
    "\n",
    "This notebook shows you how to build and use vector databases that power intelligent educational platforms like Canopy.\n",
    "\n",
    "You've already deployed Milvus through GitOps - now let's see how it works! We'll convert course content into searchable vectors and demonstrate how students can find relevant materials by meaning, not just keywords.\n",
    "\n",
    "Let's build your vector database! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9789051",
   "metadata": {},
   "source": [
    "## 📦 Install Required Packages\n",
    "\n",
    "Install the Python packages needed for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08886914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymilvus==2.5.0\n",
      "  Downloading pymilvus-2.5.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting sentence-transformers==3.0.1\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting scikit-learn==1.4.2\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting matplotlib==3.8.4\n",
      "  Downloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting marshmallow==3.20.2\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting boto3==1.34.103\n",
      "  Downloading boto3-1.34.103-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting docling==2.39.0\n",
      "  Downloading docling-2.39.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub==0.33.2\n",
      "  Downloading huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain-core==0.3.68\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-openai==0.3.27\n",
      "  Downloading langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: setuptools>69 in /opt/app-root/lib64/python3.11/site-packages (from pymilvus==2.5.0) (75.8.2)\n",
      "Collecting grpcio<=1.67.1,>=1.49.1 (from pymilvus==2.5.0)\n",
      "  Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /opt/app-root/lib64/python3.11/site-packages (from pymilvus==2.5.0) (4.25.8)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /opt/app-root/lib64/python3.11/site-packages (from pymilvus==2.5.0) (1.1.1)\n",
      "Collecting ujson>=2.0.0 (from pymilvus==2.5.0)\n",
      "  Downloading ujson-5.11.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /opt/app-root/lib64/python3.11/site-packages (from pymilvus==2.5.0) (2.2.3)\n",
      "Collecting milvus-lite>=2.4.0 (from pymilvus==2.5.0)\n",
      "  Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl.metadata (10.0 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers==3.0.1)\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers==3.0.1) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers==3.0.1)\n",
      "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers==3.0.1) (2.2.6)\n",
      "Requirement already satisfied: scipy in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers==3.0.1) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /opt/app-root/lib64/python3.11/site-packages (from sentence-transformers==3.0.1) (11.2.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn==1.4.2) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib64/python3.11/site-packages (from scikit-learn==1.4.2) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib==3.8.4) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib==3.8.4) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib==3.8.4) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib==3.8.4) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib==3.8.4) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib==3.8.4) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/app-root/lib64/python3.11/site-packages (from matplotlib==3.8.4) (2.9.0.post0)\n",
      "Collecting botocore<1.35.0,>=1.34.103 (from boto3==1.34.103)\n",
      "  Downloading botocore-1.34.162-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/app-root/lib64/python3.11/site-packages (from boto3==1.34.103) (1.0.1)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3==1.34.103)\n",
      "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/app-root/lib64/python3.11/site-packages (from docling==2.39.0) (2.11.7)\n",
      "Collecting docling-core<3.0.0,>=2.39.0 (from docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading docling_core-2.45.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting docling-ibm-models<4.0.0,>=3.4.4 (from docling==2.39.0)\n",
      "  Downloading docling_ibm_models-3.9.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting docling-parse<5.0.0,>=4.0.0 (from docling==2.39.0)\n",
      "  Downloading docling_parse-4.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from docling==2.39.0)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pypdfium2<5.0.0,>=4.30.0 (from docling==2.39.0)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.3.0 (from docling==2.39.0)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.2 in /opt/app-root/lib64/python3.11/site-packages (from docling==2.39.0) (2.32.4)\n",
      "Collecting easyocr<2.0,>=1.7 (from docling==2.39.0)\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /opt/app-root/lib64/python3.11/site-packages (from docling==2.39.0) (2025.6.15)\n",
      "Collecting rtree<2.0.0,>=1.3.0 (from docling==2.39.0)\n",
      "  Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting typer<0.17.0,>=0.12.5 (from docling==2.39.0)\n",
      "  Downloading typer-0.16.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting python-docx<2.0.0,>=1.1.2 (from docling==2.39.0)\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-pptx<2.0.0,>=1.0.2 (from docling==2.39.0)\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from docling==2.39.0)\n",
      "  Downloading beautifulsoup4-4.13.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting marko<3.0.0,>=2.1.2 (from docling==2.39.0)\n",
      "  Downloading marko-2.2.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting openpyxl<4.0.0,>=3.1.5 (from docling==2.39.0)\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting lxml<6.0.0,>=4.0.0 (from docling==2.39.0)\n",
      "  Downloading lxml-5.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting pluggy<2.0.0,>=1.0.0 (from docling==2.39.0)\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pylatexenc<3.0,>=2.10 (from docling==2.39.0)\n",
      "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub==0.33.2) (3.18.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub==0.33.2)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub==0.33.2) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub==0.33.2) (4.14.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub==0.33.2)\n",
      "  Downloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core==0.3.68)\n",
      "  Downloading langsmith-0.4.20-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core==0.3.68)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.68)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib==3.8.4)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting openai<2.0.0,>=1.86.0 (from langchain-openai==0.3.27)\n",
      "  Downloading openai-1.102.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.3.27)\n",
      "  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->docling==2.39.0)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/app-root/lib64/python3.11/site-packages (from botocore<1.35.0,>=1.34.103->boto3==1.34.103) (1.26.20)\n",
      "Collecting jsonschema<5.0.0,>=4.16.0 (from docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /opt/app-root/lib64/python3.11/site-packages (from docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0) (0.9.0)\n",
      "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading latex2mathml-3.78.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting torchvision<1,>=0 (from docling-ibm-models<4.0.0,>=3.4.4->docling==2.39.0)\n",
      "  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<4.0.0,>=3.4.4->docling==2.39.0)\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opencv-python-headless<5.0.0.0,>=4.6.0.66 (from docling-ibm-models<4.0.0,>=3.4.4->docling==2.39.0)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting safetensors<1,>=0.4.3 (from safetensors[torch]<1,>=0.4.3->docling-ibm-models<4.0.0,>=3.4.4->docling==2.39.0)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting accelerate<2.0.0,>=1.2.1 (from docling-ibm-models<4.0.0,>=3.4.4->docling==2.39.0)\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting scikit-image (from easyocr<2.0,>=1.7->docling==2.39.0)\n",
      "  Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr<2.0,>=1.7->docling==2.39.0)\n",
      "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting Shapely (from easyocr<2.0,>=1.7->docling==2.39.0)\n",
      "  Downloading shapely-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pyclipper (from easyocr<2.0,>=1.7->docling==2.39.0)\n",
      "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr<2.0,>=1.7->docling==2.39.0)\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core==0.3.68)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.11/site-packages (from langsmith>=0.3.45->langchain-core==0.3.68) (0.28.1)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.3.45->langchain-core==0.3.68)\n",
      "  Downloading orjson-3.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.3.45->langchain-core==0.3.68)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.3.45->langchain-core==0.3.68)\n",
      "  Downloading zstandard-0.24.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib64/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.27) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/app-root/lib64/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.27) (1.9.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.27)\n",
      "  Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib64/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.27) (1.3.1)\n",
      "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.1.5->docling==2.39.0)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas>=1.2.4->pymilvus==2.5.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.11/site-packages (from pandas>=1.2.4->pymilvus==2.5.0) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/app-root/lib64/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->docling==2.39.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/app-root/lib64/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->docling==2.39.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/app-root/lib64/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->docling==2.39.0) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.8.4) (1.17.0)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling==2.39.0)\n",
      "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests<3.0.0,>=2.32.2->docling==2.39.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests<3.0.0,>=2.32.2->docling==2.39.0) (3.10)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.3.27)\n",
      "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers==3.0.1)\n",
      "  Downloading transformers-4.55.3-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.55.1-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.54.0-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/app-root/lib64/python3.11/site-packages (from typer<0.17.0,>=0.12.5->docling==2.39.0) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer<0.17.0,>=0.12.5->docling==2.39.0)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/app-root/lib64/python3.11/site-packages (from typer<0.17.0,>=0.12.5->docling==2.39.0) (14.1.0)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib64/python3.11/site-packages (from accelerate<2.0.0,>=1.2.1->docling-ibm-models<4.0.0,>=3.4.4->docling==2.39.0) (7.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core==0.3.68) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core==0.3.68) (0.16.0)\n",
      "Collecting attrs>=19.2.0 (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<4.0.0,>=3.4.4->docling==2.39.0)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.39.0->docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading rpds_py-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/app-root/lib64/python3.11/site-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling==2.39.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.11/site-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling==2.39.0) (2.19.1)\n",
      "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers==3.0.1)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->easyocr<2.0,>=1.7->docling==2.39.0)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr<2.0,>=1.7->docling==2.39.0)\n",
      "  Downloading tifffile-2025.8.28-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr<2.0,>=1.7->docling==2.39.0)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/app-root/lib64/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.17.0,>=0.12.5->docling==2.39.0) (0.1.2)\n",
      "Collecting multiprocess>=0.70.15 (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
      "Collecting dill>=0.4.0 (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.39.0->docling==2.39.0)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Downloading pymilvus-2.5.0-py3-none-any.whl (212 kB)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m169.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m208.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "Downloading boto3-1.34.103-py3-none-any.whl (139 kB)\n",
      "Downloading docling-2.39.0-py3-none-any.whl (185 kB)\n",
      "Downloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Downloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "Downloading langchain_openai-0.3.27-py3-none-any.whl (70 kB)\n",
      "Downloading beautifulsoup4-4.13.5-py3-none-any.whl (105 kB)\n",
      "Downloading botocore-1.34.162-py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m204.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docling_core-2.45.0-py3-none-any.whl (163 kB)\n",
      "Downloading docling_ibm_models-3.9.0-py3-none-any.whl (86 kB)\n",
      "Downloading docling_parse-4.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m208.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m226.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m190.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m219.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.4.20-py3-none-any.whl (377 kB)\n",
      "Downloading lxml-5.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m213.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marko-2.2.0-py3-none-any.whl (42 kB)\n",
      "Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl (55.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 MB\u001b[0m \u001b[31m205.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.102.0-py3-none-any.whl (812 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.0/812.0 kB\u001b[0m \u001b[31m675.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m232.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (507 kB)\n",
      "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m586.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m208.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m208.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m214.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m204.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m553.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m183.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m161.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m274.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m168.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m173.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m183.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m151.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m134.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m141.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m140.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.53.3-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m157.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.16.1-py3-none-any.whl (46 kB)\n",
      "Downloading ujson-5.11.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (57 kB)\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading latex2mathml-3.78.0-py3-none-any.whl (73 kB)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m209.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m670.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m202.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m219.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m207.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
      "Downloading zstandard-0.24.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m216.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m446.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m442.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
      "Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m209.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m214.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m603.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
      "Downloading tifffile-2025.8.28-py3-none-any.whl (231 kB)\n",
      "Downloading multiprocess-0.70.18-py311-none-any.whl (144 kB)\n",
      "Downloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Building wheels for collected packages: pylatexenc\n",
      "  Building wheel for pylatexenc (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136863 sha256=eadd53f0419550bd456279ac89f007a2402572abfd7442e16bbfdce213ce1e9d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-afakvds2/wheels/b1/7a/33/9fdd892f784ed4afda62b685ae3703adf4c91aa0f524c28f03\n",
      "Successfully built pylatexenc\n",
      "Installing collected packages: python-bidi, pylatexenc, pyclipper, nvidia-cusparselt-cu12, mpmath, filetype, zstandard, XlsxWriter, ujson, triton, tifffile, tenacity, sympy, soupsieve, shellingham, Shapely, safetensors, rtree, rpds-py, regex, pypdfium2, pluggy, packaging, orjson, opencv-python-headless, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, networkx, mpire, milvus-lite, MarkupSafe, marko, lxml, latex2mathml, jsonref, jsonpointer, jiter, imageio, hf-xet, grpcio, fsspec, et-xmlfile, dill, attrs, tiktoken, scikit-learn, requests-toolbelt, referencing, python-pptx, python-docx, openpyxl, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, matplotlib, marshmallow, lazy-loader, jsonpatch, jsonlines, jinja2, huggingface-hub, botocore, beautifulsoup4, typer, tokenizers, scikit-image, s3transfer, pymilvus, pydantic-settings, openai, nvidia-cusolver-cu12, langsmith, jsonschema-specifications, transformers, torch, semchunk, langchain-core, jsonschema, boto3, torchvision, sentence-transformers, langchain-openai, docling-core, accelerate, easyocr, docling-parse, docling-ibm-models, docling\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "  Attempting uninstall: requests-toolbelt\n",
      "    Found existing installation: requests-toolbelt 0.10.1\n",
      "    Uninstalling requests-toolbelt-0.10.1:\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.10.3\n",
      "    Uninstalling matplotlib-3.10.3:\n",
      "      Successfully uninstalled matplotlib-3.10.3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.37.38\n",
      "    Uninstalling botocore-1.37.38:\n",
      "      Successfully uninstalled botocore-1.37.38\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.11.5\n",
      "    Uninstalling s3transfer-0.11.5:\n",
      "      Successfully uninstalled s3transfer-0.11.5\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.37.38\n",
      "    Uninstalling boto3-1.37.38:\n",
      "      Successfully uninstalled boto3-1.37.38\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kfp 2.9.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 Shapely-2.1.1 XlsxWriter-3.2.5 accelerate-1.10.1 attrs-25.3.0 beautifulsoup4-4.13.5 boto3-1.34.103 botocore-1.34.162 dill-0.4.0 docling-2.39.0 docling-core-2.45.0 docling-ibm-models-3.9.0 docling-parse-4.2.3 easyocr-1.7.2 et-xmlfile-2.0.0 filetype-1.2.0 fsspec-2025.7.0 grpcio-1.67.1 hf-xet-1.1.9 huggingface-hub-0.33.2 imageio-2.37.0 jinja2-3.1.6 jiter-0.10.0 jsonlines-3.1.0 jsonpatch-1.33 jsonpointer-3.0.0 jsonref-1.1.0 jsonschema-4.25.1 jsonschema-specifications-2025.4.1 langchain-core-0.3.68 langchain-openai-0.3.27 langsmith-0.4.20 latex2mathml-3.78.0 lazy-loader-0.4 lxml-5.4.0 marko-2.2.0 marshmallow-3.20.2 matplotlib-3.8.4 milvus-lite-2.5.1 mpire-2.10.2 mpmath-1.3.0 multiprocess-0.70.18 networkx-3.5 ninja-1.13.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 openai-1.102.0 opencv-python-headless-4.12.0.88 openpyxl-3.1.5 orjson-3.11.3 packaging-24.2 pluggy-1.6.0 pyclipper-1.3.0.post6 pydantic-settings-2.10.1 pylatexenc-2.10 pymilvus-2.5.0 pypdfium2-4.30.0 python-bidi-0.6.6 python-docx-1.2.0 python-pptx-1.0.2 referencing-0.36.2 regex-2025.7.34 requests-toolbelt-1.0.0 rpds-py-0.27.1 rtree-1.4.1 s3transfer-0.10.4 safetensors-0.6.2 scikit-image-0.25.2 scikit-learn-1.4.2 semchunk-2.2.2 sentence-transformers-3.0.1 shellingham-1.5.4 soupsieve-2.8 sympy-1.14.0 tenacity-9.1.2 tifffile-2025.8.28 tiktoken-0.11.0 tokenizers-0.21.4 torch-2.8.0 torchvision-0.23.0 transformers-4.53.3 triton-3.4.0 typer-0.16.1 ujson-5.11.0 zstandard-0.24.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install necessary libraries (run in a cell if needed)\n",
    "!pip install -q pymilvus==2.5.0 sentence-transformers==3.0.1 scikit-learn==1.4.2 matplotlib==3.8.4 marshmallow==3.20.2 boto3==1.34.103 docling==2.39.0 huggingface-hub==0.33.2 langchain-core==0.3.68 langchain-openai==0.3.27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0875c35f",
   "metadata": {},
   "source": [
    "## 📚 Import Libraries\n",
    "\n",
    "Import the tools we'll use for vector database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9a822-a34d-4755-b954-d76d2bf897f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for vector database operations\n",
    "from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8acfa6d-a20f-4028-ba4c-f6be7cfb39ec",
   "metadata": {},
   "source": [
    "## 🗃️ Populate Your Vector Database\n",
    "\n",
    "Let's connect to Milvus and set up a collection to store course content as searchable vectors.\n",
    "\n",
    "We'll use the `all-MiniLM-L6-v2` embedding model which creates 384-dimensional vectors. The vector dimensions must match your chosen embedding model exactly! There are many different embedding models available on Hugging Face - check the **[Embedding LLM Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)** to compare them.\n",
    "\n",
    "`all-MiniLM-L6-v2` isn't the top performer, but it's one of the best in its size class and downloads/runs quickly for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5167bb0-7c73-41ad-a330-ef84356555fa",
   "metadata": {},
   "source": [
    "## 🔗 Connect to Your Milvus Database\n",
    "\n",
    "Connect to the Milvus instance you deployed via GitOps.\n",
    "\n",
    "‼️⚠️ IMPORTANT ⚠️‼️\n",
    "\n",
    "Add your username and cluster domain that were shared with you. This connects to your Milvus instance in the `{username}-test` namespace.\n",
    "\n",
    "### 🖼️ Optional: Explore Milvus Attu Web Interface\n",
    "\n",
    "Before we start coding, you can visually explore your empty Milvus database using Attu (Milvus web UI):\n",
    "\n",
    "**Attu URL**: `https://milvus-test-attu-{username}-test.{cluster_domain}`\n",
    "\n",
    "Replace `{username}` and `{cluster_domain}` with your values. You'll see an empty database initially - perfect for understanding the starting point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a8b57-2f33-43ed-be0e-2f9ddd0bb57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT! Add your username and cluster domain here\n",
    "username = \"<USER_NAME>\"\n",
    "cluster_domain = \"<CLUSTER_DOMAIN>\"\n",
    "\n",
    "# Define collection name for our educational content vectors\n",
    "collection_name = \"vectordb_collection\"\n",
    "\n",
    "connections.connect(\n",
    "    uri=f\"http://milvus-test.{username}-test.svc.cluster.local:19530\",\n",
    "    alias=\"default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a04e28-c0c2-453a-afb3-26d64f81b61b",
   "metadata": {},
   "source": [
    "## 🧹 Clean Up Previous Runs\n",
    "\n",
    "Remove any existing collections to start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597e32f-9e61-48d6-952c-4580f19791f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove existing collection if it exists\n",
    "if utility.has_collection(collection_name):\n",
    "    utility.drop_collection(collection_name)\n",
    "\n",
    "print(f\"Collection list after cleanup: {utility.list_collections()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f308a-70cc-4954-bd7f-377050bc8d31",
   "metadata": {},
   "source": [
    "## 📋 Define Database Schema\n",
    "\n",
    "Vector databases need a schema just like traditional databases. Our schema defines what each record contains: a unique ID and a vector embedding.\n",
    "\n",
    "This structure is essential for storing and managing vector embeddings efficiently - Milvus needs to know exactly what fields to expect and their data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d13cc-1884-44a3-a4ab-2b2ed655426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databases need a schema that defines the structure of each record\n",
    "# Our schema has two fields: an identifier and a vector embedding\n",
    "\n",
    "# Define the primary key field for unique record identification\n",
    "id_field = FieldSchema(\n",
    "    name=\"id\",\n",
    "    dtype=DataType.INT64,\n",
    "    is_primary=True,\n",
    "    auto_id=False\n",
    ")\n",
    "\n",
    "# Specify embedding model and its output dimension\n",
    "embedding_model = \"all-MiniLM-L6-v2\"  # Hugging Face model name\n",
    "embedding_dim = 384  # Vector size must match model output\n",
    "\n",
    "# Define the vector field to hold embedding values\n",
    "embedding_field = FieldSchema(\n",
    "    name=\"embedding\",\n",
    "    dtype=DataType.FLOAT_VECTOR,\n",
    "    dim=embedding_dim\n",
    ")\n",
    "\n",
    "# Assemble collection schema combining ID and embedding fields\n",
    "schema = CollectionSchema(\n",
    "    fields=[id_field, embedding_field],\n",
    "    description=\"Educational content vectors\",\n",
    "    enable_dynamic_field=False  # Strict schema enforcement\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa222056-2372-4530-81ff-cf9e662ca7c0",
   "metadata": {},
   "source": [
    "## 🏗️ Create the Collection\n",
    "\n",
    "A collection in Milvus is like a table in a traditional database - it's where your embedding vectors will be stored, indexed, and queried.\n",
    "\n",
    "We'll configure it with strong consistency to ensure you always get the most up-to-date data when searching for educational content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1594974-484a-4b48-bbfc-4166f393d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Milvus collection with our schema and configuration\n",
    "collection = Collection(\n",
    "    name=collection_name, \n",
    "    schema=schema, \n",
    "    using='default',  # Use default connection\n",
    "    shards_num=2,  # Number of data shards for distribution\n",
    "    consistency_level=\"Strong\"  # Ensures latest data is always returned\n",
    ")\n",
    "\n",
    "print(f\"Collection: {collection.schema}\\n\")\n",
    "\n",
    "print(f\"Collection list: {utility.list_collections()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fc3356-8e5d-4cd4-86a7-9a9bad767884",
   "metadata": {},
   "source": [
    "## 💾 Store Content in Vector Database\n",
    "\n",
    "Time to save our course content vectors in Milvus for searching!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a335e56-4058-4b5c-b11a-fee2399230ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding model from Hugging Face\n",
    "model = SentenceTransformer(embedding_model)\n",
    "\n",
    "sentences = [\"Introduction to Machine Learning covers supervised learning algorithms.\",\n",
    "             \"Machine Learning fundamentals include supervised algorithm techniques.\",\n",
    "             \"Computer Science department offers advanced database systems courses.\",\n",
    "             \"Students can access research databases through the library portal.\"]\n",
    "\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb03b66-f384-4c89-ba37-326420ab07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare educational content vectors for database insertion\n",
    "data = [\n",
    "    {\"id\": i, \"embedding\": vec.tolist()}  # Convert numpy array to list\n",
    "    for i, vec in enumerate(embeddings)\n",
    "]\n",
    "\n",
    "# Insert the vectors into our Milvus collection\n",
    "collection.insert(data=data)\n",
    "\n",
    "# Create an index for fast similarity searching\n",
    "# COSINE metric is perfect for semantic similarity\n",
    "collection.create_index(\n",
    "    field_name=\"embedding\",\n",
    "    index_params={\n",
    "        \"metric_type\": \"COSINE\",  # Cosine similarity for semantic search\n",
    "        \"index_type\": \"IVF_FLAT\",  # Inverted file index\n",
    "        \"params\": {\"nlist\": 128}  # Number of clusters for indexing\n",
    "    },\n",
    "    index_name=\"idx\"\n",
    ")\n",
    "\n",
    "# Commit changes and load collection into memory for searching\n",
    "collection.flush()  # Ensure data is written to disk\n",
    "collection.load()   # Load collection into memory for fast queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e39c2",
   "metadata": {},
   "source": [
    "### 📊 Check Attu After Insertion\n",
    "\n",
    "Now visit your Attu web interface again to see the data visualization:\n",
    "\n",
    "**Attu URL**: `https://milvus-test-attu-<USER_NAME>-test.<CLUSTER_DOMAIN>`\n",
    "\n",
    "You'll now see your collection with 4 educational content vectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8c4b0e-d3db-4615-b445-00212788dff1",
   "metadata": {},
   "source": [
    "## 🔎 Search Your Vector Database\n",
    "\n",
    "Now the exciting part! Let's search for educational content using semantic similarity. We stored four course-related sentences - two about Machine Learning, two about other topics.\n",
    "\n",
    "We'll search with \"What AI ethics topics are covered in the curriculum?\" and see how Machine Learning content scores higher than unrelated academic content. This demonstrates exactly how Canopy finds relevant course materials when students ask questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec26c4-6105-47b0-b430-2505f38ab8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate semantic search with educational query\n",
    "print(\"\\n🔁 VECTOR DATABASE RETRIEVAL DEMO\")\n",
    "query = \"What AI ethics topics are covered in the curriculum?\"\n",
    "query_vector = model.encode([query])  # Convert query to vector\n",
    "\n",
    "# Search our vector database for semantically similar content\n",
    "results = collection.search(\n",
    "    data=query_vector,\n",
    "    anns_field=\"embedding\",  # Field containing our vectors\n",
    "    param={\"metric_type\": \"COSINE\"},  # Use cosine similarity\n",
    "    limit=3,  # Return top 3 matches\n",
    "    output_fields=[\"embedding\"]  # Include original vectors in results\n",
    ")\n",
    "\n",
    "# Map result IDs back to original text\n",
    "id_to_text = {i: sentence for i, sentence in enumerate(sentences)}\n",
    "\n",
    "# Display the search results with similarity scores\n",
    "print(f\"\\n📌 Query: '{query}'\\n\")\n",
    "print(\"📥 Top matches:\\n\")\n",
    "for match in results[0]:\n",
    "    match_id = match.id\n",
    "    score = match.score  # Cosine similarity score (higher = more similar)\n",
    "    matched_text = id_to_text.get(match_id, \"[Unknown]\")\n",
    "\n",
    "    print(f\"🆔 ID: {match_id}\")\n",
    "    print(f\"🧠 Text: {matched_text}\")\n",
    "    print(f\"📏 Score: {score:.4f}\\n\")\n",
    "\n",
    "print(\"✅ Notice: ML-related content gets higher similarity scores!\")\n",
    "print(\"🎓 This is exactly how Canopy finds relevant course materials!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766da69d-2a18-4851-aab9-c3a391247c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up - close connection and remove collection (optional)\n",
    "collection.release()\n",
    "#utility.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79l5mpxxbw",
   "metadata": {},
   "source": [
    "## 🎉 You've Set up your Vector Database!\n",
    "\n",
    "**What you accomplished:**\n",
    "- Connected to your deployed Milvus instance via GitOps\n",
    "- Learned how embedding models convert text to searchable vectors\n",
    "- Created a database schema and collection for educational content  \n",
    "- Tested semantic similarity with course materials\n",
    "- Demonstrated how vector search finds relevant content by meaning\n",
    "\n",
    "**Key insights:**\n",
    "- Related educational content (like ML courses) gets high similarity scores\n",
    "- Unrelated content gets filtered out automatically\n",
    "- This enables intelligent search that understands context, not just keywords\n",
    "\n",
    "This is the foundation that powers Canopy's intelligent search capabilities. Students can now ask questions and get relevant answers based on meaning!\n",
    "\n",
    "Go back to the instructions to integrate this vector database with LlamaStack for complete RAG functionality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

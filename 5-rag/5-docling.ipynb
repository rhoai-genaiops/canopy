{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ£ Document Intelligence with Docling: Unlocking Complex Academic Content\n",
    "\n",
    "This notebook demonstrates **Document Intelligence** - the advanced capability to understand and process complex documents like research papers, academic materials, and structured content that traditional RAG systems struggle with.\n",
    "\n",
    "**The Challenge:**\n",
    "Imagine trying to build an educational AI assistant using only basic text extraction from research papers. You'd lose:\n",
    "- **ğŸ“Š Table data** with crucial research findings\n",
    "- **ğŸ§® Mathematical formulas** and scientific notation  \n",
    "- **ğŸ“ˆ Charts and figures** that provide key insights\n",
    "- **ğŸ›ï¸ Document structure** like sections, references, and metadata\n",
    "- **ğŸ“ Multi-column layouts** common in academic papers\n",
    "\n",
    "**The Solution: Docling**\n",
    "Docling is an advanced document processing toolkit that acts like a brilliant research assistant, understanding the **meaning and structure** of complex academic documents.\n",
    "\n",
    "**What You'll Build:**\n",
    "- **ğŸ”¬ Intelligent Document Processor**: Extract rich content from complex PDFs\n",
    "- **ğŸ“š Enhanced RAG System**: Query tables, formulas, and structured content  \n",
    "- **ğŸ¯ Academic AI Assistant**: Answer questions using complete document understanding\n",
    "- **âš¡ Production Pipeline**: Handle real-world educational materials at scale\n",
    "\n",
    "**Why This Matters:**\n",
    "Traditional RAG systems often fail with academic content, missing critical information trapped in tables or losing context from complex layouts. Docling transforms these challenging documents into fully searchable, queryable knowledge.\n",
    "\n",
    "#### Let's build document intelligence that truly understands academic content! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Install Required Packages\n",
    "\n",
    "Install the Python packages needed for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q llama_stack_client fire dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Import Libraries for Document Intelligence\n",
    "\n",
    "Import the essential libraries for building our document intelligence RAG system with Docling processing capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for document intelligence and RAG\n",
    "import uuid      # For generating unique vector database identifiers\n",
    "import requests  # For HTTP communication with Docling service and document fetching\n",
    "import base64    # For encoding binary data if needed (images, complex formats)\n",
    "import json      # For handling Docling API responses and metadata\n",
    "import os        # System utilities\n",
    "import sys       # System path management\n",
    "sys.path.append('..')  # Add parent directory for custom utilities\n",
    "\n",
    "# LlamaStack client and RAG-specific classes\n",
    "from llama_stack_client import LlamaStackClient  # Main interface for RAG operations\n",
    "from llama_stack_client import RAGDocument  # Represents documents for RAG ingestion\n",
    "from llama_stack_client.types.shared.content_delta import TextDelta, ToolCallDelta  # For streaming responses\n",
    "\n",
    "# Display and utility imports\n",
    "from src.utils import step_printer  # For progress tracking\n",
    "from termcolor import cprint        # For colorized output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ What is Docling?\n",
    "\n",
    "**Docling** is an advanced document processing toolkit that transforms complex academic materials into intelligent, searchable content. It understands document structure, preserves relationships, and converts everything into AI-ready formats.\n",
    "\n",
    "### ğŸ”§ The Docling Pipeline\n",
    "\n",
    "**Phase 1: Document Analysis** ğŸ“„\n",
    "```\n",
    "PDF Input â†’ Layout Detection â†’ Structure Analysis â†’ Content Extraction\n",
    "```\n",
    "\n",
    "**Phase 2: Content Enhancement** ğŸ”§  \n",
    "```\n",
    "Raw Text â†’ Table Extraction â†’ Formula Recognition â†’ Figure Processing\n",
    "```\n",
    "\n",
    "**Phase 3: RAG Integration** ğŸ—„ï¸\n",
    "```\n",
    "Intelligent Chunking â†’ Vector Embeddings â†’ Enhanced RAG Search\n",
    "```\n",
    "\n",
    "### ğŸ§  Traditional vs Document Intelligence\n",
    "\n",
    "**Traditional Processing:**\n",
    "```\n",
    "PDF â†’ Simple Text â†’ Basic Chunks â†’ Limited RAG\n",
    "âŒ Loses tables, formulas, structure, figures\n",
    "```\n",
    "\n",
    "**Docling Intelligence:**\n",
    "```\n",
    "PDF â†’ Structured Content â†’ Smart Chunks â†’ Enhanced RAG\n",
    "âœ… Preserves tables, formulas, layout, relationships\n",
    "```\n",
    "\n",
    "**Why This Matters:** Traditional RAG systems miss information trapped in tables, lose context from figures, and struggle with academic layouts. Docling solves these problems by understanding document structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— Connect to LlamaStack\n",
    "\n",
    "Connect to LlamaStack - the AI engine that orchestrates all RAG operations. LlamaStack acts as the central hub that coordinates:\n",
    "- Vector database operations (storage and retrieval)\n",
    "- Document processing and chunking  \n",
    "- LLM inference with retrieved context\n",
    "- Agent workflows and tool usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LlamaStack Connection Setup ===\n",
    "# Connect to the LlamaStack server that coordinates document intelligence\n",
    "base_url = \"http://llama-stack-service:8321\"\n",
    "\n",
    "# Configure provider data (none needed for this demo)\n",
    "provider_data = None\n",
    "\n",
    "# Create the LlamaStack client for document intelligence and RAG\n",
    "client = LlamaStackClient(\n",
    "    base_url=base_url,\n",
    "    provider_data=provider_data\n",
    ")\n",
    "\n",
    "print(f\"Connected to LlamaStack server\")\n",
    "\n",
    "# === Model Configuration for Document Intelligence ===\n",
    "# Configure the LLM that will reason about processed documents\n",
    "model_id = \"llama32\"       # Llama 3.2 model for text generation\n",
    "temperature = 0.0         # Deterministic responses for factual document queries  \n",
    "max_tokens = 4096         # Larger context for complex document reasoning\n",
    "stream = True             # Stream responses for better user experience\n",
    "\n",
    "# Configure sampling strategy for consistent, factual responses\n",
    "if temperature > 0.0:\n",
    "    top_p = 0.95\n",
    "    strategy = {\"type\": \"top_p\", \"temperature\": temperature, \"top_p\": top_p}\n",
    "else:\n",
    "    strategy = {\"type\": \"greedy\"}  # Deterministic for factual document analysis\n",
    "\n",
    "# Package parameters for LlamaStack inference API\n",
    "sampling_params = {\n",
    "    \"strategy\": strategy,\n",
    "    \"max_tokens\": max_tokens,\n",
    "}\n",
    "\n",
    "# Display configuration\n",
    "print(f\"Model Configuration:\")\n",
    "print(f\"  â€¢ Model: {model_id}\")\n",
    "print(f\"  â€¢ Strategy: {strategy['type']}\")  \n",
    "print(f\"  â€¢ Max Tokens: {max_tokens} (enhanced for complex documents)\")\n",
    "print(f\"  â€¢ Stream: {stream}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Docling Processing Function Implementation\n",
    "\n",
    "This function connects to the Docling service and processes documents through the intelligent pipeline we just described.\n",
    "\n",
    "### ğŸ¯ Function Capabilities\n",
    "\n",
    "**Input:** Document URL (PDF, DOCX, etc.)  \n",
    "**Output:** Structured Markdown with preserved intelligence  \n",
    "**Processing:** Full document analysis with table, formula, and structure preservation\n",
    "\n",
    "### ğŸ”§ What This Function Does\n",
    "\n",
    "```\n",
    "Document URL â†’ Docling Service â†’ Intelligent Analysis â†’ Structured Markdown\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "- **ğŸ”— Service Integration**: Connects to deployed Docling service in the cluster\n",
    "- **ğŸ“Š Advanced Processing**: Layout detection, table extraction, formula recognition\n",
    "- **â° Academic Optimization**: Handles complex documents with 3-minute timeout\n",
    "- **ğŸ§  Structure Preservation**: Returns enhanced Markdown with document intelligence\n",
    "\n",
    "### âš¡ Processing Expectations\n",
    "\n",
    "**Time:** 1-2 minutes for complex academic documents  \n",
    "**Why:** Deep analysis of layout, tables, formulas, and structure  \n",
    "**Result:** Dramatically better RAG performance with complete content preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docling_processing(url):\n",
    "    \"\"\"\n",
    "    Process a document URL using the Docling service for intelligent content extraction.\n",
    "    \n",
    "    This function performs advanced document analysis including:\n",
    "    - Layout detection and structure analysis\n",
    "    - Table extraction with preserved formatting  \n",
    "    - Mathematical formula recognition\n",
    "    - Figure and chart processing\n",
    "    - Multi-column layout understanding\n",
    "    - Semantic content structuring\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL of the document to process (PDF, DOCX, etc.)\n",
    "        \n",
    "    Returns:\n",
    "        str: Structured Markdown content with preserved document intelligence\n",
    "        \n",
    "    Note: Processing can take 1-2 minutes for complex academic documents\n",
    "    \"\"\"\n",
    "    # === Docling Service Configuration ===\n",
    "    # Connect to the deployed Docling service in the cluster\n",
    "    api_address = \"http://docling-v0-7-0-predictor.ai501.svc.cluster.local:5001\"\n",
    "    \n",
    "    # Configure headers (no authentication needed for cluster-internal service)\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    print(f\"ğŸ”— Docling Service: {api_address}/v1alpha/convert/source\")\n",
    "    print(f\"ğŸ“„ Processing document: {url}\")\n",
    "    print(f\"â° This may take 1-2 minutes for complex documents...\")\n",
    "    \n",
    "    # === Document Processing Request ===\n",
    "    # Configure Docling to extract maximum intelligence from the document\n",
    "    payload = {\n",
    "        \"http_sources\": [{\"url\": url}],              # Document source\n",
    "        \"options\": {\n",
    "            \"to_formats\": [\"md\"],                    # Output as structured Markdown\n",
    "            \"image_export_mode\": \"placeholder\"      # Handle images appropriately\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # === Submit Processing Request ===\n",
    "        # Send document to Docling for intelligent analysis\n",
    "        response = requests.post(\n",
    "            f\"{api_address}/v1alpha/convert/source\",\n",
    "            json=payload,\n",
    "            headers=headers,\n",
    "            timeout=180  # 3-minute timeout for complex documents\n",
    "        )\n",
    "        \n",
    "        # Check for successful processing\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # === Extract Processed Content ===\n",
    "        # Docling returns structured Markdown with preserved document intelligence\n",
    "        result_data = response.json()\n",
    "        md_content = result_data[\"document\"][\"md_content\"]\n",
    "        \n",
    "        print(f\"âœ… Document processing complete!\")\n",
    "        print(f\"ğŸ“Š Processed content length: {len(md_content)} characters\")\n",
    "        \n",
    "        return md_content\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"â° Processing timeout - complex documents may need more time\")\n",
    "        raise\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ Docling processing failed: {e}\")\n",
    "        raise\n",
    "    except KeyError as e:\n",
    "        print(f\"âŒ Unexpected response format: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Document Processing Demonstration\n",
    "\n",
    "Let's test Docling's document intelligence on a complex academic paper. We'll use a real research paper that contains:\n",
    "- **ğŸ“Š Tables** with numerical data and results\n",
    "- **ğŸ§® Mathematical formulas** and equations  \n",
    "- **ğŸ“ˆ Figures** and charts with captions\n",
    "- **ğŸ“ Multi-column layout** typical of academic papers\n",
    "- **ğŸ›ï¸ Structured sections** like Abstract, Methods, Results, References\n",
    "\n",
    "**Example Document:** We'll process an ArXiv research paper that demonstrates the full complexity of academic content that traditional text extraction would struggle with.\n",
    "\n",
    "### ğŸ”¬ Intelligent Processing in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Select Complex Academic Document ===\n",
    "# Choose a research paper with tables, formulas, and complex structure\n",
    "# This ArXiv paper contains the kind of complex content that showcases Docling's capabilities\n",
    "\n",
    "# Option 1: Computer Vision research paper with tables and technical content\n",
    "url = \"https://arxiv.org/pdf/2404.14661\"\n",
    "\n",
    "# Alternative papers for testing (comment/uncomment as needed):\n",
    "# url = \"https://arxiv.org/pdf/2006.07156\"  # Machine Learning paper with mathematical content\n",
    "# url = \"https://raw.githubusercontent.com/rhoai-genaiops/deploy-lab/main/university-data/canopy-in-botany.pdf\"  # Simpler PDF for comparison\n",
    "\n",
    "print(f\"ğŸ¯ Selected document: {url}\")\n",
    "print(f\"ğŸ“‹ This paper likely contains tables, formulas, figures, and structured sections\")\n",
    "print(f\"âš¡ Starting intelligent document processing...\")\n",
    "\n",
    "# === Process Document with Docling Intelligence ===\n",
    "# This will take 1-2 minutes as Docling performs comprehensive analysis\n",
    "md_content = docling_processing(url)\n",
    "\n",
    "print(f\"\\nğŸ‰ Document intelligence processing complete!\")\n",
    "print(f\"ğŸ“Š Content preview (first 500 characters):\")\n",
    "print(f\"{'='*60}\")\n",
    "print(md_content[:500] + \"...\" if len(md_content) > 500 else md_content)\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"ğŸ“ˆ Total processed content: {len(md_content)} characters\")\n",
    "print(f\"ğŸ“ Docling has extracted and structured the complete document content!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Document Processing Demonstration\n",
    "\n",
    "Let's test Docling's document intelligence on a complex academic paper. We'll use a real research paper that contains:\n",
    "- **ğŸ“Š Tables** with numerical data and results\n",
    "- **ğŸ§® Mathematical formulas** and equations  \n",
    "- **ğŸ“ˆ Figures** and charts with captions\n",
    "- **ğŸ“ Multi-column layout** typical of academic papers\n",
    "- **ğŸ›ï¸ Structured sections** like Abstract, Methods, Results, References\n",
    "\n",
    "**Example Document:** We'll process an ArXiv research paper that demonstrates the full complexity of academic content that traditional text extraction would struggle with.\n",
    "\n",
    "### ğŸ”¬ Intelligent Processing in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ƒï¸ Create Vector Database for RAG\n",
    "\n",
    "Set up a vector database where documents will be stored for retrieval. This is the **Storage Layer** of our RAG architecture.\n",
    "\n",
    "**What happens here:**\n",
    "1. **Registration**: Tell LlamaStack about your vector database configuration\n",
    "2. **Embedding Model**: Specify which model converts text to vectors (we use `all-MiniLM-L6-v2`)\n",
    "3. **Dimensions**: Set vector size (384 dimensions for our chosen model)\n",
    "4. **Provider**: Connect to your Milvus database deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 1: Create Unique Vector Database ===\n",
    "# Generate a unique identifier for this vector database instance\n",
    "# Using UUID ensures no conflicts when multiple users run this notebook\n",
    "vector_db_id = f\"test_vector_db_{uuid.uuid4()}\"\n",
    "print(f\"ğŸ“Š Created vector database ID: {vector_db_id}\")\n",
    "\n",
    "# === STEP 2: Register Vector Database for Document Intelligence ===\n",
    "# Configure the vector database to handle intelligently-processed documents\n",
    "client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,                      # Unique identifier for this database\n",
    "    embedding_model=\"all-MiniLM-L6-v2\",            # Sentence transformer for embeddings\n",
    "    embedding_dimension=384,                        # Vector dimensions (must match model)\n",
    "    provider_id=\"milvus\",                           # Use Milvus as the vector store backend\n",
    ")\n",
    "\n",
    "print(f\"âœ… Registered vector database for document intelligence:\")\n",
    "print(f\"  â€¢ Database ID: {vector_db_id}\")\n",
    "print(f\"  â€¢ Embedding Model: all-MiniLM-L6-v2 (384 dimensions)\")\n",
    "print(f\"  â€¢ Provider: Milvus vector database\")\n",
    "print(f\"  â€¢ Ready for Docling-processed content ingestion!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Document Processing with Docling\n",
    "\n",
    "This is where the **Document Intelligence** comes into action! We'll use Docling to process a complex academic document that contains tables, formulas, and structured content.\n",
    "\n",
    "**The Docling Process:**\n",
    "1. **Connect** to Docling service \n",
    "2. **Process** PDF with intelligent analysis\n",
    "3. **Extract** structured content with preserved meaning\n",
    "4. **Prepare** for RAG ingestion with enhanced metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 3: Ingest Docling-Processed Content into RAG System ===\n",
    "# Create a RAGDocument object with the intelligently-processed content\n",
    "documents = [\n",
    "    RAGDocument(\n",
    "        document_id=f\"docling-processed-doc\",        # Unique identifier for this document\n",
    "        content=md_content,                          # The Docling-processed Markdown content\n",
    "        metadata={                                   # Enhanced metadata for complex documents\n",
    "            \"source_url\": url,                       # Original document URL\n",
    "            \"processing_method\": \"docling\",          # Processing pipeline used\n",
    "            \"document_type\": \"academic_paper\",       # Content classification\n",
    "            \"has_tables\": True,                      # Contains structured tabular data\n",
    "            \"has_formulas\": True,                    # Contains mathematical content\n",
    "            \"has_figures\": True,                     # Contains visual elements\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“š Preparing to ingest intelligently-processed document:\")\n",
    "print(f\"  â€¢ Document ID: docling-processed-doc\")\n",
    "print(f\"  â€¢ Content length: {len(md_content)} characters\")\n",
    "print(f\"  â€¢ Processing method: Docling document intelligence\")\n",
    "print(f\"  â€¢ Content includes: tables, formulas, figures, and structured text\")\n",
    "\n",
    "# === STEP 4: Use LlamaStack RAG Tool for Intelligent Chunking ===\n",
    "# The RAG tool will automatically chunk the content optimally for retrieval\n",
    "try:\n",
    "    client.tool_runtime.rag_tool.insert(\n",
    "        documents=documents,                         # List of RAGDocument objects to process\n",
    "        vector_db_id=vector_db_id,                  # Target vector database\n",
    "        chunk_size_in_tokens=512,                   # Optimal chunk size for academic content\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Document ingestion complete!\")\n",
    "    print(f\"ğŸ¯ Docling-processed content is now searchable via semantic similarity!\")\n",
    "    print(f\"ğŸ“Š Complex academic content (tables, formulas, figures) is now queryable!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Document ingestion failed: {e}\")\n",
    "    print(f\"ğŸ’¡ Check Docling processing and vector database configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Testing Document Intelligence RAG System\n",
    "\n",
    "Now let's test our enhanced RAG system with queries that showcase Docling's document intelligence capabilities. We'll ask questions that would require understanding of:\n",
    "- **ğŸ“Š Tabular data** and structured information\n",
    "- **ğŸ§® Mathematical content** and technical details\n",
    "- **ğŸ“ˆ Research findings** and experimental results\n",
    "- **ğŸ›ï¸ Document structure** and relationships\n",
    "\n",
    "**The Power of Document Intelligence:**\n",
    "Traditional text extraction would miss most of this information, but Docling's intelligent processing preserves the meaning and structure that enables accurate, comprehensive answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries for the processed document\n",
    "queries = [\n",
    "    \"What is the PRFXception?\",\n",
    "    \"The accuracy values of overall model prediction and residual cross-validation for five regions in southeast Tibet and four regions in northwest Yunnan\"\n",
    "]\n",
    "\n",
    "for prompt in queries:\n",
    "    cprint(f\"\\nUser> {prompt}\", \"blue\")\n",
    "    \n",
    "    # RAG retrieval call - find relevant chunks from the vector database\n",
    "    rag_response = client.tool_runtime.rag_tool.query(\n",
    "        content=prompt, \n",
    "        vector_db_ids=[vector_db_id],\n",
    "        query_config={\n",
    "            \"chunk_template\": \"Result {index}\\nContent: {chunk.content}\\nMetadata: {metadata}\\n\",\n",
    "        },\n",
    "        )\n",
    "\n",
    "    cprint(rag_response)\n",
    "\n",
    "    cprint(f\"\\n--- RAG Metadata ---\", \"yellow\")\n",
    "    cprint(rag_response.metadata, \"cyan\")\n",
    "\n",
    "    # Create messages for the LLM with system prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "\n",
    "    # Combine the user query with retrieved context from RAG\n",
    "    prompt_context = rag_response.content\n",
    "    extended_prompt = f\"Please answer the given query using the context below.\\n\\nCONTEXT:\\n{prompt_context}\\n\\nQUERY:\\n{prompt}\"\n",
    "    messages.append({\"role\": \"user\", \"content\": extended_prompt})\n",
    "\n",
    "    # Get response from the LLM using the enhanced prompt\n",
    "    response = client.inference.chat_completion(\n",
    "        messages=messages,\n",
    "        model_id=model_id,\n",
    "        sampling_params=sampling_params,\n",
    "        stream=stream,\n",
    "    )\n",
    "    \n",
    "    # Print the streaming response\n",
    "    cprint(\"inference> \", color=\"magenta\", end='')\n",
    "    if stream:\n",
    "        for chunk in response:\n",
    "            response_delta = chunk.event.delta\n",
    "            if isinstance(response_delta, TextDelta):\n",
    "                cprint(response_delta.text, color=\"magenta\", end='')\n",
    "            elif isinstance(response_delta, ToolCallDelta):\n",
    "                cprint(response_delta.tool_call, color=\"magenta\", end='')\n",
    "    else:\n",
    "        cprint(response.completion_message.content, color=\"magenta\")\n",
    "\n",
    "    cprint(f\"\\n--- End of RAG Answer ---\", \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ You've Built a Document Intelligence RAG System!\n",
    "\n",
    "**What you accomplished:**\n",
    "- **ğŸ”¬ Document Intelligence**: Processed complex academic papers with Docling's advanced capabilities\n",
    "- **ğŸ“Š Structured Content Extraction**: Preserved tables, formulas, figures, and document hierarchy\n",
    "- **ğŸ—„ï¸ Enhanced Vector Storage**: Stored intelligently-processed content in Milvus for semantic search\n",
    "- **ğŸ¤– Intelligent Querying**: Built a RAG system that understands complex academic content\n",
    "- **âš¡ Production Pipeline**: Created a scalable workflow for real-world educational materials\n",
    "\n",
    "**Key Technical Insights:**\n",
    "- **Document Intelligence vs Basic Extraction**: Docling preserves meaning and structure that simple text extraction would lose\n",
    "- **Three-Phase Processing**: Analysis â†’ Enhancement â†’ RAG Integration creates comprehensive understanding\n",
    "- **Semantic Understanding**: Complex documents become queryable by meaning, not just keywords\n",
    "- **Metadata Enrichment**: Enhanced document metadata enables better retrieval and filtering\n",
    "\n",
    "**Document Intelligence vs Traditional RAG:**\n",
    "| Traditional RAG | Document Intelligence RAG |\n",
    "|-----------------|---------------------------|\n",
    "| âŒ Loses table structure | âœ… Preserves tabular relationships |\n",
    "| âŒ Misses mathematical content | âœ… Handles formulas and equations |\n",
    "| âŒ Ignores document layout | âœ… Understands multi-column layouts |\n",
    "| âŒ Basic text chunks | âœ… Intelligent content structuring |\n",
    "| âŒ Limited metadata | âœ… Rich semantic metadata |\n",
    "\n",
    "Your document intelligence system can now understand and query the most complex academic content - transforming how educational institutions handle knowledge discovery and research! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
